I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.7.5 locally
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:05:00.0
Total memory: 11.92GiB
Free memory: 11.81GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x26a0640
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 1 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:08:00.0
Total memory: 11.92GiB
Free memory: 11.81GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 1 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 1:   Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:08:00.0)
2016-09-12 11:32:05.175766: step 10, duration = 0.045
2016-09-12 11:32:05.624964: step 20, duration = 0.045
2016-09-12 11:32:06.073860: step 30, duration = 0.045
2016-09-12 11:32:06.523547: step 40, duration = 0.045
2016-09-12 11:32:06.973439: step 50, duration = 0.045
2016-09-12 11:32:07.422984: step 60, duration = 0.045
2016-09-12 11:32:07.872454: step 70, duration = 0.045
2016-09-12 11:32:08.320651: step 80, duration = 0.045
2016-09-12 11:32:08.769608: step 90, duration = 0.045
2016-09-12 11:32:09.218916: step 100, duration = 0.045
2016-09-12 11:32:09.669121: step 110, duration = 0.045
2016-09-12 11:32:10.118548: step 120, duration = 0.045
2016-09-12 11:32:10.567409: step 130, duration = 0.045
2016-09-12 11:32:11.016987: step 140, duration = 0.045
2016-09-12 11:32:11.466573: step 150, duration = 0.045
2016-09-12 11:32:11.916099: step 160, duration = 0.045
2016-09-12 11:32:12.365005: step 170, duration = 0.045
2016-09-12 11:32:12.814420: step 180, duration = 0.045
2016-09-12 11:32:13.263447: step 190, duration = 0.045
2016-09-12 11:32:13.712342: step 200, duration = 0.045
2016-09-12 11:32:14.161539: step 210, duration = 0.045
2016-09-12 11:32:14.611081: step 220, duration = 0.045
2016-09-12 11:32:15.060191: step 230, duration = 0.045
2016-09-12 11:32:15.510162: step 240, duration = 0.045
2016-09-12 11:32:15.959542: step 250, duration = 0.045
2016-09-12 11:32:16.409133: step 260, duration = 0.045
2016-09-12 11:32:16.859161: step 270, duration = 0.045
2016-09-12 11:32:17.308814: step 280, duration = 0.045
2016-09-12 11:32:17.758621: step 290, duration = 0.045
2016-09-12 11:32:18.207625: step 300, duration = 0.045
2016-09-12 11:32:18.657133: step 310, duration = 0.045
2016-09-12 11:32:19.106003: step 320, duration = 0.045
2016-09-12 11:32:19.557487: step 330, duration = 0.045
2016-09-12 11:32:20.009853: step 340, duration = 0.045
2016-09-12 11:32:20.463111: step 350, duration = 0.045
2016-09-12 11:32:20.916141: step 360, duration = 0.045
2016-09-12 11:32:21.369064: step 370, duration = 0.045
2016-09-12 11:32:21.822109: step 380, duration = 0.045
2016-09-12 11:32:22.276350: step 390, duration = 0.045
fake 2016-09-12 11:32:22.683474: Forward-backward across 400 steps, 0.045 +/- 0.002 sec / batch
