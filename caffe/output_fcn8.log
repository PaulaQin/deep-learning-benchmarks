I1026 00:29:15.023110 44939 caffe.cpp:217] Using GPUs 0
I1026 00:29:15.355823 44939 caffe.cpp:222] GPU 0: Tesla K40m
I1026 00:29:15.766186 44939 solver.cpp:48] Initializing solver from parameters: 
base_lr: 0.01
display: 1
max_iter: 80
lr_policy: "fixed"
solver_mode: GPU
device_id: 0
net: "fcn8.prototxt"
train_state {
  level: 0
  stage: ""
}
I1026 00:29:15.766266 44939 solver.cpp:91] Creating training net from net file: fcn8.prototxt
I1026 00:29:15.766723 44939 net.cpp:58] Initializing net from parameters: 
name: "FFN"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  data_param {
    source: "fake_data26752.lmdb"
    batch_size: 8192
    backend: LMDB
  }
}
layer {
  name: "H1"
  type: "InnerProduct"
  bottom: "data"
  top: "H1"
  inner_product_param {
    num_output: 2048
  }
}
layer {
  name: "H1_A"
  type: "Sigmoid"
  bottom: "H1"
  top: "H1"
}
layer {
  name: "H2"
  type: "InnerProduct"
  bottom: "H1"
  top: "H2"
  inner_product_param {
    num_output: 2048
  }
}
layer {
  name: "H2_A"
  type: "Sigmoid"
  bottom: "H2"
  top: "H2"
}
layer {
  name: "H3"
  type: "InnerProduct"
  bottom: "H2"
  top: "H3"
  inner_product_param {
    num_output: 2048
  }
}
layer {
  name: "H3_A"
  type: "Sigmoid"
  bottom: "H3"
  top: "H3"
}
layer {
  name: "H4"
  type: "InnerProduct"
  bottom: "H3"
  top: "H4"
  inner_product_param {
    num_output: 2048
  }
}
layer {
  name: "H4_A"
  type: "Sigmoid"
  bottom: "H4"
  top: "H4"
}
layer {
  name: "H5"
  type: "InnerProduct"
  bottom: "H4"
  top: "H5"
  inner_product_param {
    num_output: 2048
  }
}
layer {
  name: "H5_A"
  type: "Sigmoid"
  bottom: "H5"
  top: "H5"
}
layer {
  name: "H6"
  type: "InnerProduct"
  bottom: "H5"
  top: "H6"
  inner_product_param {
    num_output: 2048
  }
}
layer {
  name: "H6_A"
  type: "Sigmoid"
  bottom: "H6"
  top: "H6"
}
layer {
  name: "L"
  type: "InnerProduct"
  bottom: "H6"
  top: "L"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "L"
  bottom: "label"
  top: "loss"
}
I1026 00:29:15.766856 44939 layer_factory.hpp:77] Creating layer data
I1026 00:29:15.771461 44939 net.cpp:100] Creating Layer data
I1026 00:29:15.771491 44939 net.cpp:408] data -> data
I1026 00:29:15.771535 44939 net.cpp:408] data -> label
I1026 00:29:15.773309 44944 db_lmdb.cpp:35] Opened lmdb fake_data26752.lmdb
I1026 00:29:15.785269 44939 data_layer.cpp:41] output data size: 8192,1,1,512
I1026 00:29:15.816241 44939 net.cpp:150] Setting up data
I1026 00:29:15.816468 44939 net.cpp:157] Top shape: 8192 1 1 512 (4194304)
I1026 00:29:15.816500 44939 net.cpp:157] Top shape: 8192 (8192)
I1026 00:29:15.816504 44939 net.cpp:165] Memory required for data: 16809984
I1026 00:29:15.816512 44939 layer_factory.hpp:77] Creating layer H1
I1026 00:29:15.816541 44939 net.cpp:100] Creating Layer H1
I1026 00:29:15.816570 44939 net.cpp:434] H1 <- data
I1026 00:29:15.816598 44939 net.cpp:408] H1 -> H1
I1026 00:29:15.821467 44939 net.cpp:150] Setting up H1
I1026 00:29:15.821501 44939 net.cpp:157] Top shape: 8192 2048 (16777216)
I1026 00:29:15.821504 44939 net.cpp:165] Memory required for data: 83918848
I1026 00:29:15.821524 44939 layer_factory.hpp:77] Creating layer H1_A
I1026 00:29:15.821539 44939 net.cpp:100] Creating Layer H1_A
I1026 00:29:15.821544 44939 net.cpp:434] H1_A <- H1
I1026 00:29:15.821568 44939 net.cpp:395] H1_A -> H1 (in-place)
I1026 00:29:15.821578 44939 net.cpp:150] Setting up H1_A
I1026 00:29:15.821583 44939 net.cpp:157] Top shape: 8192 2048 (16777216)
I1026 00:29:15.821588 44939 net.cpp:165] Memory required for data: 151027712
I1026 00:29:15.821594 44939 layer_factory.hpp:77] Creating layer H2
I1026 00:29:15.821599 44939 net.cpp:100] Creating Layer H2
I1026 00:29:15.821604 44939 net.cpp:434] H2 <- H1
I1026 00:29:15.821609 44939 net.cpp:408] H2 -> H2
I1026 00:29:15.831652 44939 net.cpp:150] Setting up H2
I1026 00:29:15.831684 44939 net.cpp:157] Top shape: 8192 2048 (16777216)
I1026 00:29:15.831688 44939 net.cpp:165] Memory required for data: 218136576
I1026 00:29:15.831707 44939 layer_factory.hpp:77] Creating layer H2_A
I1026 00:29:15.831755 44939 net.cpp:100] Creating Layer H2_A
I1026 00:29:15.831768 44939 net.cpp:434] H2_A <- H2
I1026 00:29:15.831776 44939 net.cpp:395] H2_A -> H2 (in-place)
I1026 00:29:15.831787 44939 net.cpp:150] Setting up H2_A
I1026 00:29:15.831794 44939 net.cpp:157] Top shape: 8192 2048 (16777216)
I1026 00:29:15.831799 44939 net.cpp:165] Memory required for data: 285245440
I1026 00:29:15.831810 44939 layer_factory.hpp:77] Creating layer H3
I1026 00:29:15.831818 44939 net.cpp:100] Creating Layer H3
I1026 00:29:15.831822 44939 net.cpp:434] H3 <- H2
I1026 00:29:15.831830 44939 net.cpp:408] H3 -> H3
I1026 00:29:15.841675 44939 net.cpp:150] Setting up H3
I1026 00:29:15.841723 44939 net.cpp:157] Top shape: 8192 2048 (16777216)
I1026 00:29:15.841728 44939 net.cpp:165] Memory required for data: 352354304
I1026 00:29:15.841747 44939 layer_factory.hpp:77] Creating layer H3_A
I1026 00:29:15.841763 44939 net.cpp:100] Creating Layer H3_A
I1026 00:29:15.841784 44939 net.cpp:434] H3_A <- H3
I1026 00:29:15.841794 44939 net.cpp:395] H3_A -> H3 (in-place)
I1026 00:29:15.841806 44939 net.cpp:150] Setting up H3_A
I1026 00:29:15.841810 44939 net.cpp:157] Top shape: 8192 2048 (16777216)
I1026 00:29:15.841814 44939 net.cpp:165] Memory required for data: 419463168
I1026 00:29:15.841817 44939 layer_factory.hpp:77] Creating layer H4
I1026 00:29:15.841825 44939 net.cpp:100] Creating Layer H4
I1026 00:29:15.841828 44939 net.cpp:434] H4 <- H3
I1026 00:29:15.841836 44939 net.cpp:408] H4 -> H4
I1026 00:29:15.852282 44945 blocking_queue.cpp:50] Waiting for data
I1026 00:29:15.852839 44939 net.cpp:150] Setting up H4
I1026 00:29:15.852872 44939 net.cpp:157] Top shape: 8192 2048 (16777216)
I1026 00:29:15.852879 44939 net.cpp:165] Memory required for data: 486572032
I1026 00:29:15.852891 44939 layer_factory.hpp:77] Creating layer H4_A
I1026 00:29:15.852907 44939 net.cpp:100] Creating Layer H4_A
I1026 00:29:15.852913 44939 net.cpp:434] H4_A <- H4
I1026 00:29:15.852936 44939 net.cpp:395] H4_A -> H4 (in-place)
I1026 00:29:15.852955 44939 net.cpp:150] Setting up H4_A
I1026 00:29:15.852962 44939 net.cpp:157] Top shape: 8192 2048 (16777216)
I1026 00:29:15.852967 44939 net.cpp:165] Memory required for data: 553680896
I1026 00:29:15.852969 44939 layer_factory.hpp:77] Creating layer H5
I1026 00:29:15.852988 44939 net.cpp:100] Creating Layer H5
I1026 00:29:15.852993 44939 net.cpp:434] H5 <- H4
I1026 00:29:15.852999 44939 net.cpp:408] H5 -> H5
I1026 00:29:15.862515 44939 net.cpp:150] Setting up H5
I1026 00:29:15.862558 44939 net.cpp:157] Top shape: 8192 2048 (16777216)
I1026 00:29:15.862571 44939 net.cpp:165] Memory required for data: 620789760
I1026 00:29:15.862918 44939 layer_factory.hpp:77] Creating layer H5_A
I1026 00:29:15.862931 44939 net.cpp:100] Creating Layer H5_A
I1026 00:29:15.862936 44939 net.cpp:434] H5_A <- H5
I1026 00:29:15.862942 44939 net.cpp:395] H5_A -> H5 (in-place)
I1026 00:29:15.862953 44939 net.cpp:150] Setting up H5_A
I1026 00:29:15.862958 44939 net.cpp:157] Top shape: 8192 2048 (16777216)
I1026 00:29:15.862962 44939 net.cpp:165] Memory required for data: 687898624
I1026 00:29:15.862965 44939 layer_factory.hpp:77] Creating layer H6
I1026 00:29:15.862972 44939 net.cpp:100] Creating Layer H6
I1026 00:29:15.862977 44939 net.cpp:434] H6 <- H5
I1026 00:29:15.862984 44939 net.cpp:408] H6 -> H6
I1026 00:29:15.873003 44939 net.cpp:150] Setting up H6
I1026 00:29:15.873044 44939 net.cpp:157] Top shape: 8192 2048 (16777216)
I1026 00:29:15.873049 44939 net.cpp:165] Memory required for data: 755007488
I1026 00:29:15.873061 44939 layer_factory.hpp:77] Creating layer H6_A
I1026 00:29:15.873072 44939 net.cpp:100] Creating Layer H6_A
I1026 00:29:15.873077 44939 net.cpp:434] H6_A <- H6
I1026 00:29:15.873100 44939 net.cpp:395] H6_A -> H6 (in-place)
I1026 00:29:15.873113 44939 net.cpp:150] Setting up H6_A
I1026 00:29:15.873117 44939 net.cpp:157] Top shape: 8192 2048 (16777216)
I1026 00:29:15.873121 44939 net.cpp:165] Memory required for data: 822116352
I1026 00:29:15.873124 44939 layer_factory.hpp:77] Creating layer L
I1026 00:29:15.873155 44939 net.cpp:100] Creating Layer L
I1026 00:29:15.873160 44939 net.cpp:434] L <- H6
I1026 00:29:15.873167 44939 net.cpp:408] L -> L
I1026 00:29:15.876477 44945 blocking_queue.cpp:50] Waiting for data
I1026 00:29:15.879215 44939 net.cpp:150] Setting up L
I1026 00:29:15.879230 44939 net.cpp:157] Top shape: 8192 1000 (8192000)
I1026 00:29:15.879233 44939 net.cpp:165] Memory required for data: 854884352
I1026 00:29:15.879241 44939 layer_factory.hpp:77] Creating layer loss
I1026 00:29:15.879262 44939 net.cpp:100] Creating Layer loss
I1026 00:29:15.879266 44939 net.cpp:434] loss <- L
I1026 00:29:15.879271 44939 net.cpp:434] loss <- label
I1026 00:29:15.879292 44939 net.cpp:408] loss -> loss
I1026 00:29:15.879324 44939 layer_factory.hpp:77] Creating layer loss
I1026 00:29:15.897986 44945 blocking_queue.cpp:50] Waiting for data
I1026 00:29:15.899826 44939 net.cpp:150] Setting up loss
I1026 00:29:15.899858 44939 net.cpp:157] Top shape: (1)
I1026 00:29:15.899863 44939 net.cpp:160]     with loss weight 1
I1026 00:29:15.899901 44939 net.cpp:165] Memory required for data: 854884356
I1026 00:29:15.899924 44939 net.cpp:226] loss needs backward computation.
I1026 00:29:15.899930 44939 net.cpp:226] L needs backward computation.
I1026 00:29:15.899933 44939 net.cpp:226] H6_A needs backward computation.
I1026 00:29:15.899937 44939 net.cpp:226] H6 needs backward computation.
I1026 00:29:15.899941 44939 net.cpp:226] H5_A needs backward computation.
I1026 00:29:15.899945 44939 net.cpp:226] H5 needs backward computation.
I1026 00:29:15.899948 44939 net.cpp:226] H4_A needs backward computation.
I1026 00:29:15.899952 44939 net.cpp:226] H4 needs backward computation.
I1026 00:29:15.899955 44939 net.cpp:226] H3_A needs backward computation.
I1026 00:29:15.899960 44939 net.cpp:226] H3 needs backward computation.
I1026 00:29:15.899962 44939 net.cpp:226] H2_A needs backward computation.
I1026 00:29:15.899966 44939 net.cpp:226] H2 needs backward computation.
I1026 00:29:15.899968 44939 net.cpp:226] H1_A needs backward computation.
I1026 00:29:15.899972 44939 net.cpp:226] H1 needs backward computation.
I1026 00:29:15.899991 44939 net.cpp:228] data does not need backward computation.
I1026 00:29:15.899996 44939 net.cpp:270] This network produces output loss
I1026 00:29:15.900010 44939 net.cpp:283] Network initialization done.
I1026 00:29:15.900070 44939 solver.cpp:60] Solver scaffolding done.
I1026 00:29:15.900519 44939 caffe.cpp:251] Starting Optimization
I1026 00:29:15.900542 44939 solver.cpp:279] Solving FFN
I1026 00:29:15.900547 44939 solver.cpp:280] Learning Rate Policy: fixed
I1026 00:29:15.913357 44945 blocking_queue.cpp:50] Waiting for data
I1026 00:29:15.922013 44945 blocking_queue.cpp:50] Waiting for data
I1026 00:29:15.930562 44945 blocking_queue.cpp:50] Waiting for data
I1026 00:29:15.938956 44945 blocking_queue.cpp:50] Waiting for data
I1026 00:29:15.946913 44945 blocking_queue.cpp:50] Waiting for data
I1026 00:29:15.955270 44945 blocking_queue.cpp:50] Waiting for data
I1026 00:29:15.963536 44945 blocking_queue.cpp:50] Waiting for data
I1026 00:29:16.061358 44945 blocking_queue.cpp:50] Waiting for data
I1026 00:29:16.069286 44945 blocking_queue.cpp:50] Waiting for data
I1026 00:29:16.105921 44939 solver.cpp:228] Iteration 0, loss = 6.90776
I1026 00:29:16.105976 44939 solver.cpp:244]     Train net output #0: loss = 6.90776 (* 1 = 6.90776 loss)
I1026 00:29:16.105989 44939 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I1026 00:29:16.554133 44939 solver.cpp:228] Iteration 1, loss = 6.90775
I1026 00:29:16.554198 44939 solver.cpp:244]     Train net output #0: loss = 6.90775 (* 1 = 6.90775 loss)
I1026 00:29:16.554210 44939 sgd_solver.cpp:106] Iteration 1, lr = 0.01
I1026 00:29:17.003520 44939 solver.cpp:228] Iteration 2, loss = 6.90774
I1026 00:29:17.003573 44939 solver.cpp:244]     Train net output #0: loss = 6.90774 (* 1 = 6.90774 loss)
I1026 00:29:17.003582 44939 sgd_solver.cpp:106] Iteration 2, lr = 0.01
I1026 00:29:17.454592 44939 solver.cpp:228] Iteration 3, loss = 6.90776
I1026 00:29:17.454643 44939 solver.cpp:244]     Train net output #0: loss = 6.90776 (* 1 = 6.90776 loss)
I1026 00:29:17.454682 44939 sgd_solver.cpp:106] Iteration 3, lr = 0.01
I1026 00:29:17.902732 44939 solver.cpp:228] Iteration 4, loss = 6.90771
I1026 00:29:17.902783 44939 solver.cpp:244]     Train net output #0: loss = 6.90771 (* 1 = 6.90771 loss)
I1026 00:29:17.902791 44939 sgd_solver.cpp:106] Iteration 4, lr = 0.01
I1026 00:29:18.352577 44939 solver.cpp:228] Iteration 5, loss = 6.90773
I1026 00:29:18.352627 44939 solver.cpp:244]     Train net output #0: loss = 6.90773 (* 1 = 6.90773 loss)
I1026 00:29:18.352635 44939 sgd_solver.cpp:106] Iteration 5, lr = 0.01
I1026 00:29:18.802347 44939 solver.cpp:228] Iteration 6, loss = 6.90773
I1026 00:29:18.802404 44939 solver.cpp:244]     Train net output #0: loss = 6.90773 (* 1 = 6.90773 loss)
I1026 00:29:18.802414 44939 sgd_solver.cpp:106] Iteration 6, lr = 0.01
I1026 00:29:19.252305 44939 solver.cpp:228] Iteration 7, loss = 6.90775
I1026 00:29:19.252369 44939 solver.cpp:244]     Train net output #0: loss = 6.90775 (* 1 = 6.90775 loss)
I1026 00:29:19.252383 44939 sgd_solver.cpp:106] Iteration 7, lr = 0.01
I1026 00:29:19.698539 44939 solver.cpp:228] Iteration 8, loss = 6.90778
I1026 00:29:19.698621 44939 solver.cpp:244]     Train net output #0: loss = 6.90778 (* 1 = 6.90778 loss)
I1026 00:29:19.698631 44939 sgd_solver.cpp:106] Iteration 8, lr = 0.01
I1026 00:29:20.146538 44939 solver.cpp:228] Iteration 9, loss = 6.90784
I1026 00:29:20.146606 44939 solver.cpp:244]     Train net output #0: loss = 6.90784 (* 1 = 6.90784 loss)
I1026 00:29:20.146618 44939 sgd_solver.cpp:106] Iteration 9, lr = 0.01
I1026 00:29:20.597136 44939 solver.cpp:228] Iteration 10, loss = 6.90779
I1026 00:29:20.597189 44939 solver.cpp:244]     Train net output #0: loss = 6.90779 (* 1 = 6.90779 loss)
I1026 00:29:20.597198 44939 sgd_solver.cpp:106] Iteration 10, lr = 0.01
I1026 00:29:21.048799 44939 solver.cpp:228] Iteration 11, loss = 6.9077
I1026 00:29:21.048862 44939 solver.cpp:244]     Train net output #0: loss = 6.9077 (* 1 = 6.9077 loss)
I1026 00:29:21.048872 44939 sgd_solver.cpp:106] Iteration 11, lr = 0.01
I1026 00:29:21.498560 44939 solver.cpp:228] Iteration 12, loss = 6.90773
I1026 00:29:21.498613 44939 solver.cpp:244]     Train net output #0: loss = 6.90773 (* 1 = 6.90773 loss)
I1026 00:29:21.498621 44939 sgd_solver.cpp:106] Iteration 12, lr = 0.01
I1026 00:29:21.948042 44939 solver.cpp:228] Iteration 13, loss = 6.90788
I1026 00:29:21.948094 44939 solver.cpp:244]     Train net output #0: loss = 6.90788 (* 1 = 6.90788 loss)
I1026 00:29:21.948104 44939 sgd_solver.cpp:106] Iteration 13, lr = 0.01
I1026 00:29:22.397317 44939 solver.cpp:228] Iteration 14, loss = 6.90772
I1026 00:29:22.397366 44939 solver.cpp:244]     Train net output #0: loss = 6.90772 (* 1 = 6.90772 loss)
I1026 00:29:22.397375 44939 sgd_solver.cpp:106] Iteration 14, lr = 0.01
I1026 00:29:22.843607 44939 solver.cpp:228] Iteration 15, loss = 6.90782
I1026 00:29:22.843657 44939 solver.cpp:244]     Train net output #0: loss = 6.90782 (* 1 = 6.90782 loss)
I1026 00:29:22.843667 44939 sgd_solver.cpp:106] Iteration 15, lr = 0.01
I1026 00:29:23.296952 44939 solver.cpp:228] Iteration 16, loss = 6.90781
I1026 00:29:23.296998 44939 solver.cpp:244]     Train net output #0: loss = 6.90781 (* 1 = 6.90781 loss)
I1026 00:29:23.297005 44939 sgd_solver.cpp:106] Iteration 16, lr = 0.01
I1026 00:29:23.744434 44939 solver.cpp:228] Iteration 17, loss = 6.90783
I1026 00:29:23.744487 44939 solver.cpp:244]     Train net output #0: loss = 6.90783 (* 1 = 6.90783 loss)
I1026 00:29:23.744496 44939 sgd_solver.cpp:106] Iteration 17, lr = 0.01
I1026 00:29:24.193171 44939 solver.cpp:228] Iteration 18, loss = 6.90796
I1026 00:29:24.193219 44939 solver.cpp:244]     Train net output #0: loss = 6.90796 (* 1 = 6.90796 loss)
I1026 00:29:24.193229 44939 sgd_solver.cpp:106] Iteration 18, lr = 0.01
I1026 00:29:24.641521 44939 solver.cpp:228] Iteration 19, loss = 6.90775
I1026 00:29:24.641569 44939 solver.cpp:244]     Train net output #0: loss = 6.90775 (* 1 = 6.90775 loss)
I1026 00:29:24.641577 44939 sgd_solver.cpp:106] Iteration 19, lr = 0.01
I1026 00:29:25.091892 44939 solver.cpp:228] Iteration 20, loss = 6.90775
I1026 00:29:25.091938 44939 solver.cpp:244]     Train net output #0: loss = 6.90775 (* 1 = 6.90775 loss)
I1026 00:29:25.091944 44939 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I1026 00:29:25.540828 44939 solver.cpp:228] Iteration 21, loss = 6.90786
I1026 00:29:25.540877 44939 solver.cpp:244]     Train net output #0: loss = 6.90786 (* 1 = 6.90786 loss)
I1026 00:29:25.540885 44939 sgd_solver.cpp:106] Iteration 21, lr = 0.01
I1026 00:29:25.988364 44939 solver.cpp:228] Iteration 22, loss = 6.90768
I1026 00:29:25.988411 44939 solver.cpp:244]     Train net output #0: loss = 6.90768 (* 1 = 6.90768 loss)
I1026 00:29:25.988420 44939 sgd_solver.cpp:106] Iteration 22, lr = 0.01
I1026 00:29:26.439412 44939 solver.cpp:228] Iteration 23, loss = 6.90786
I1026 00:29:26.439458 44939 solver.cpp:244]     Train net output #0: loss = 6.90786 (* 1 = 6.90786 loss)
I1026 00:29:26.439466 44939 sgd_solver.cpp:106] Iteration 23, lr = 0.01
I1026 00:29:26.885578 44939 solver.cpp:228] Iteration 24, loss = 6.90777
I1026 00:29:26.885628 44939 solver.cpp:244]     Train net output #0: loss = 6.90777 (* 1 = 6.90777 loss)
I1026 00:29:26.885638 44939 sgd_solver.cpp:106] Iteration 24, lr = 0.01
I1026 00:29:27.336302 44939 solver.cpp:228] Iteration 25, loss = 6.90797
I1026 00:29:27.336349 44939 solver.cpp:244]     Train net output #0: loss = 6.90797 (* 1 = 6.90797 loss)
I1026 00:29:27.336359 44939 sgd_solver.cpp:106] Iteration 25, lr = 0.01
I1026 00:29:27.788332 44939 solver.cpp:228] Iteration 26, loss = 6.90796
I1026 00:29:27.788381 44939 solver.cpp:244]     Train net output #0: loss = 6.90796 (* 1 = 6.90796 loss)
I1026 00:29:27.788391 44939 sgd_solver.cpp:106] Iteration 26, lr = 0.01
I1026 00:29:28.237162 44939 solver.cpp:228] Iteration 27, loss = 6.90771
I1026 00:29:28.237207 44939 solver.cpp:244]     Train net output #0: loss = 6.90771 (* 1 = 6.90771 loss)
I1026 00:29:28.237213 44939 sgd_solver.cpp:106] Iteration 27, lr = 0.01
I1026 00:29:28.685274 44939 solver.cpp:228] Iteration 28, loss = 6.90789
I1026 00:29:28.685322 44939 solver.cpp:244]     Train net output #0: loss = 6.90789 (* 1 = 6.90789 loss)
I1026 00:29:28.685328 44939 sgd_solver.cpp:106] Iteration 28, lr = 0.01
I1026 00:29:29.135251 44939 solver.cpp:228] Iteration 29, loss = 6.90774
I1026 00:29:29.135301 44939 solver.cpp:244]     Train net output #0: loss = 6.90774 (* 1 = 6.90774 loss)
I1026 00:29:29.135309 44939 sgd_solver.cpp:106] Iteration 29, lr = 0.01
I1026 00:29:29.582926 44939 solver.cpp:228] Iteration 30, loss = 6.90759
I1026 00:29:29.582973 44939 solver.cpp:244]     Train net output #0: loss = 6.90759 (* 1 = 6.90759 loss)
I1026 00:29:29.582979 44939 sgd_solver.cpp:106] Iteration 30, lr = 0.01
I1026 00:29:30.033807 44939 solver.cpp:228] Iteration 31, loss = 6.9079
I1026 00:29:30.033867 44939 solver.cpp:244]     Train net output #0: loss = 6.9079 (* 1 = 6.9079 loss)
I1026 00:29:30.033876 44939 sgd_solver.cpp:106] Iteration 31, lr = 0.01
I1026 00:29:30.481559 44939 solver.cpp:228] Iteration 32, loss = 6.90759
I1026 00:29:30.481619 44939 solver.cpp:244]     Train net output #0: loss = 6.90759 (* 1 = 6.90759 loss)
I1026 00:29:30.481628 44939 sgd_solver.cpp:106] Iteration 32, lr = 0.01
I1026 00:29:30.930969 44939 solver.cpp:228] Iteration 33, loss = 6.90796
I1026 00:29:30.931013 44939 solver.cpp:244]     Train net output #0: loss = 6.90796 (* 1 = 6.90796 loss)
I1026 00:29:30.931021 44939 sgd_solver.cpp:106] Iteration 33, lr = 0.01
I1026 00:29:31.378852 44939 solver.cpp:228] Iteration 34, loss = 6.90774
I1026 00:29:31.378901 44939 solver.cpp:244]     Train net output #0: loss = 6.90774 (* 1 = 6.90774 loss)
I1026 00:29:31.378908 44939 sgd_solver.cpp:106] Iteration 34, lr = 0.01
I1026 00:29:31.826946 44939 solver.cpp:228] Iteration 35, loss = 6.90782
I1026 00:29:31.826998 44939 solver.cpp:244]     Train net output #0: loss = 6.90782 (* 1 = 6.90782 loss)
I1026 00:29:31.827008 44939 sgd_solver.cpp:106] Iteration 35, lr = 0.01
I1026 00:29:32.275250 44939 solver.cpp:228] Iteration 36, loss = 6.90793
I1026 00:29:32.275297 44939 solver.cpp:244]     Train net output #0: loss = 6.90793 (* 1 = 6.90793 loss)
I1026 00:29:32.275336 44939 sgd_solver.cpp:106] Iteration 36, lr = 0.01
I1026 00:29:32.724900 44939 solver.cpp:228] Iteration 37, loss = 6.90769
I1026 00:29:32.724948 44939 solver.cpp:244]     Train net output #0: loss = 6.90769 (* 1 = 6.90769 loss)
I1026 00:29:32.724956 44939 sgd_solver.cpp:106] Iteration 37, lr = 0.01
I1026 00:29:33.172513 44939 solver.cpp:228] Iteration 38, loss = 6.90768
I1026 00:29:33.172569 44939 solver.cpp:244]     Train net output #0: loss = 6.90768 (* 1 = 6.90768 loss)
I1026 00:29:33.172579 44939 sgd_solver.cpp:106] Iteration 38, lr = 0.01
I1026 00:29:33.620771 44939 solver.cpp:228] Iteration 39, loss = 6.90762
I1026 00:29:33.620831 44939 solver.cpp:244]     Train net output #0: loss = 6.90762 (* 1 = 6.90762 loss)
I1026 00:29:33.620838 44939 sgd_solver.cpp:106] Iteration 39, lr = 0.01
I1026 00:29:34.072010 44939 solver.cpp:228] Iteration 40, loss = 6.90784
I1026 00:29:34.072069 44939 solver.cpp:244]     Train net output #0: loss = 6.90784 (* 1 = 6.90784 loss)
I1026 00:29:34.072077 44939 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I1026 00:29:34.521483 44939 solver.cpp:228] Iteration 41, loss = 6.90778
I1026 00:29:34.521544 44939 solver.cpp:244]     Train net output #0: loss = 6.90778 (* 1 = 6.90778 loss)
I1026 00:29:34.521554 44939 sgd_solver.cpp:106] Iteration 41, lr = 0.01
I1026 00:29:34.972579 44939 solver.cpp:228] Iteration 42, loss = 6.90786
I1026 00:29:34.972636 44939 solver.cpp:244]     Train net output #0: loss = 6.90786 (* 1 = 6.90786 loss)
I1026 00:29:34.972645 44939 sgd_solver.cpp:106] Iteration 42, lr = 0.01
I1026 00:29:35.423529 44939 solver.cpp:228] Iteration 43, loss = 6.90768
I1026 00:29:35.423580 44939 solver.cpp:244]     Train net output #0: loss = 6.90768 (* 1 = 6.90768 loss)
I1026 00:29:35.423588 44939 sgd_solver.cpp:106] Iteration 43, lr = 0.01
I1026 00:29:35.870306 44939 solver.cpp:228] Iteration 44, loss = 6.90764
I1026 00:29:35.870353 44939 solver.cpp:244]     Train net output #0: loss = 6.90764 (* 1 = 6.90764 loss)
I1026 00:29:35.870362 44939 sgd_solver.cpp:106] Iteration 44, lr = 0.01
I1026 00:29:36.319963 44939 solver.cpp:228] Iteration 45, loss = 6.90793
I1026 00:29:36.320024 44939 solver.cpp:244]     Train net output #0: loss = 6.90793 (* 1 = 6.90793 loss)
I1026 00:29:36.320031 44939 sgd_solver.cpp:106] Iteration 45, lr = 0.01
I1026 00:29:36.770400 44939 solver.cpp:228] Iteration 46, loss = 6.90784
I1026 00:29:36.770459 44939 solver.cpp:244]     Train net output #0: loss = 6.90784 (* 1 = 6.90784 loss)
I1026 00:29:36.770467 44939 sgd_solver.cpp:106] Iteration 46, lr = 0.01
I1026 00:29:37.215473 44939 solver.cpp:228] Iteration 47, loss = 6.90777
I1026 00:29:37.215531 44939 solver.cpp:244]     Train net output #0: loss = 6.90777 (* 1 = 6.90777 loss)
I1026 00:29:37.215539 44939 sgd_solver.cpp:106] Iteration 47, lr = 0.01
I1026 00:29:37.663048 44939 solver.cpp:228] Iteration 48, loss = 6.90778
I1026 00:29:37.663105 44939 solver.cpp:244]     Train net output #0: loss = 6.90778 (* 1 = 6.90778 loss)
I1026 00:29:37.663115 44939 sgd_solver.cpp:106] Iteration 48, lr = 0.01
I1026 00:29:38.110498 44939 solver.cpp:228] Iteration 49, loss = 6.90776
I1026 00:29:38.110555 44939 solver.cpp:244]     Train net output #0: loss = 6.90776 (* 1 = 6.90776 loss)
I1026 00:29:38.110569 44939 sgd_solver.cpp:106] Iteration 49, lr = 0.01
I1026 00:29:38.561159 44939 solver.cpp:228] Iteration 50, loss = 6.90784
I1026 00:29:38.561219 44939 solver.cpp:244]     Train net output #0: loss = 6.90784 (* 1 = 6.90784 loss)
I1026 00:29:38.561228 44939 sgd_solver.cpp:106] Iteration 50, lr = 0.01
I1026 00:29:39.011598 44939 solver.cpp:228] Iteration 51, loss = 6.90806
I1026 00:29:39.011663 44939 solver.cpp:244]     Train net output #0: loss = 6.90806 (* 1 = 6.90806 loss)
I1026 00:29:39.011673 44939 sgd_solver.cpp:106] Iteration 51, lr = 0.01
I1026 00:29:39.460428 44939 solver.cpp:228] Iteration 52, loss = 6.90771
I1026 00:29:39.460475 44939 solver.cpp:244]     Train net output #0: loss = 6.90771 (* 1 = 6.90771 loss)
I1026 00:29:39.460516 44939 sgd_solver.cpp:106] Iteration 52, lr = 0.01
I1026 00:29:39.908874 44939 solver.cpp:228] Iteration 53, loss = 6.90782
I1026 00:29:39.908922 44939 solver.cpp:244]     Train net output #0: loss = 6.90782 (* 1 = 6.90782 loss)
I1026 00:29:39.908929 44939 sgd_solver.cpp:106] Iteration 53, lr = 0.01
I1026 00:29:40.360501 44939 solver.cpp:228] Iteration 54, loss = 6.9076
I1026 00:29:40.360559 44939 solver.cpp:244]     Train net output #0: loss = 6.9076 (* 1 = 6.9076 loss)
I1026 00:29:40.360566 44939 sgd_solver.cpp:106] Iteration 54, lr = 0.01
I1026 00:29:40.810915 44939 solver.cpp:228] Iteration 55, loss = 6.9076
I1026 00:29:40.810974 44939 solver.cpp:244]     Train net output #0: loss = 6.9076 (* 1 = 6.9076 loss)
I1026 00:29:40.810982 44939 sgd_solver.cpp:106] Iteration 55, lr = 0.01
I1026 00:29:41.259802 44939 solver.cpp:228] Iteration 56, loss = 6.90811
I1026 00:29:41.259861 44939 solver.cpp:244]     Train net output #0: loss = 6.90811 (* 1 = 6.90811 loss)
I1026 00:29:41.259871 44939 sgd_solver.cpp:106] Iteration 56, lr = 0.01
I1026 00:29:41.708458 44939 solver.cpp:228] Iteration 57, loss = 6.9078
I1026 00:29:41.708505 44939 solver.cpp:244]     Train net output #0: loss = 6.9078 (* 1 = 6.9078 loss)
I1026 00:29:41.708513 44939 sgd_solver.cpp:106] Iteration 57, lr = 0.01
I1026 00:29:42.161262 44939 solver.cpp:228] Iteration 58, loss = 6.90785
I1026 00:29:42.161309 44939 solver.cpp:244]     Train net output #0: loss = 6.90785 (* 1 = 6.90785 loss)
I1026 00:29:42.161315 44939 sgd_solver.cpp:106] Iteration 58, lr = 0.01
I1026 00:29:42.611893 44939 solver.cpp:228] Iteration 59, loss = 6.90796
I1026 00:29:42.611940 44939 solver.cpp:244]     Train net output #0: loss = 6.90796 (* 1 = 6.90796 loss)
I1026 00:29:42.611948 44939 sgd_solver.cpp:106] Iteration 59, lr = 0.01
I1026 00:29:43.057849 44939 solver.cpp:228] Iteration 60, loss = 6.9079
I1026 00:29:43.057912 44939 solver.cpp:244]     Train net output #0: loss = 6.9079 (* 1 = 6.9079 loss)
I1026 00:29:43.057922 44939 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I1026 00:29:43.506367 44939 solver.cpp:228] Iteration 61, loss = 6.90758
I1026 00:29:43.506425 44939 solver.cpp:244]     Train net output #0: loss = 6.90758 (* 1 = 6.90758 loss)
I1026 00:29:43.506433 44939 sgd_solver.cpp:106] Iteration 61, lr = 0.01
I1026 00:29:43.952956 44939 solver.cpp:228] Iteration 62, loss = 6.90794
I1026 00:29:43.953014 44939 solver.cpp:244]     Train net output #0: loss = 6.90794 (* 1 = 6.90794 loss)
I1026 00:29:43.953022 44939 sgd_solver.cpp:106] Iteration 62, lr = 0.01
I1026 00:29:44.403301 44939 solver.cpp:228] Iteration 63, loss = 6.9079
I1026 00:29:44.403359 44939 solver.cpp:244]     Train net output #0: loss = 6.9079 (* 1 = 6.9079 loss)
I1026 00:29:44.403367 44939 sgd_solver.cpp:106] Iteration 63, lr = 0.01
I1026 00:29:44.852582 44939 solver.cpp:228] Iteration 64, loss = 6.90781
I1026 00:29:44.852641 44939 solver.cpp:244]     Train net output #0: loss = 6.90781 (* 1 = 6.90781 loss)
I1026 00:29:44.852650 44939 sgd_solver.cpp:106] Iteration 64, lr = 0.01
I1026 00:29:45.301731 44939 solver.cpp:228] Iteration 65, loss = 6.90787
I1026 00:29:45.301863 44939 solver.cpp:244]     Train net output #0: loss = 6.90787 (* 1 = 6.90787 loss)
I1026 00:29:45.301872 44939 sgd_solver.cpp:106] Iteration 65, lr = 0.01
I1026 00:29:45.753471 44939 solver.cpp:228] Iteration 66, loss = 6.90799
I1026 00:29:45.753531 44939 solver.cpp:244]     Train net output #0: loss = 6.90799 (* 1 = 6.90799 loss)
I1026 00:29:45.753540 44939 sgd_solver.cpp:106] Iteration 66, lr = 0.01
I1026 00:29:46.202764 44939 solver.cpp:228] Iteration 67, loss = 6.90766
I1026 00:29:46.202826 44939 solver.cpp:244]     Train net output #0: loss = 6.90766 (* 1 = 6.90766 loss)
I1026 00:29:46.202834 44939 sgd_solver.cpp:106] Iteration 67, lr = 0.01
I1026 00:29:46.656121 44939 solver.cpp:228] Iteration 68, loss = 6.90774
I1026 00:29:46.656180 44939 solver.cpp:244]     Train net output #0: loss = 6.90774 (* 1 = 6.90774 loss)
I1026 00:29:46.656188 44939 sgd_solver.cpp:106] Iteration 68, lr = 0.01
I1026 00:29:47.107332 44939 solver.cpp:228] Iteration 69, loss = 6.90802
I1026 00:29:47.107396 44939 solver.cpp:244]     Train net output #0: loss = 6.90802 (* 1 = 6.90802 loss)
I1026 00:29:47.107408 44939 sgd_solver.cpp:106] Iteration 69, lr = 0.01
I1026 00:29:47.558066 44939 solver.cpp:228] Iteration 70, loss = 6.90764
I1026 00:29:47.558127 44939 solver.cpp:244]     Train net output #0: loss = 6.90764 (* 1 = 6.90764 loss)
I1026 00:29:47.558136 44939 sgd_solver.cpp:106] Iteration 70, lr = 0.01
I1026 00:29:48.008595 44939 solver.cpp:228] Iteration 71, loss = 6.90763
I1026 00:29:48.008647 44939 solver.cpp:244]     Train net output #0: loss = 6.90763 (* 1 = 6.90763 loss)
I1026 00:29:48.008656 44939 sgd_solver.cpp:106] Iteration 71, lr = 0.01
I1026 00:29:48.459095 44939 solver.cpp:228] Iteration 72, loss = 6.90784
I1026 00:29:48.459151 44939 solver.cpp:244]     Train net output #0: loss = 6.90784 (* 1 = 6.90784 loss)
I1026 00:29:48.459159 44939 sgd_solver.cpp:106] Iteration 72, lr = 0.01
I1026 00:29:48.906113 44939 solver.cpp:228] Iteration 73, loss = 6.90816
I1026 00:29:48.906162 44939 solver.cpp:244]     Train net output #0: loss = 6.90816 (* 1 = 6.90816 loss)
I1026 00:29:48.906168 44939 sgd_solver.cpp:106] Iteration 73, lr = 0.01
I1026 00:29:49.351824 44939 solver.cpp:228] Iteration 74, loss = 6.90771
I1026 00:29:49.351871 44939 solver.cpp:244]     Train net output #0: loss = 6.90771 (* 1 = 6.90771 loss)
I1026 00:29:49.351878 44939 sgd_solver.cpp:106] Iteration 74, lr = 0.01
I1026 00:29:49.800459 44939 solver.cpp:228] Iteration 75, loss = 6.90791
I1026 00:29:49.800518 44939 solver.cpp:244]     Train net output #0: loss = 6.90791 (* 1 = 6.90791 loss)
I1026 00:29:49.800526 44939 sgd_solver.cpp:106] Iteration 75, lr = 0.01
I1026 00:29:50.252091 44939 solver.cpp:228] Iteration 76, loss = 6.90784
I1026 00:29:50.252145 44939 solver.cpp:244]     Train net output #0: loss = 6.90784 (* 1 = 6.90784 loss)
I1026 00:29:50.252152 44939 sgd_solver.cpp:106] Iteration 76, lr = 0.01
I1026 00:29:50.701874 44939 solver.cpp:228] Iteration 77, loss = 6.90784
I1026 00:29:50.701921 44939 solver.cpp:244]     Train net output #0: loss = 6.90784 (* 1 = 6.90784 loss)
I1026 00:29:50.701928 44939 sgd_solver.cpp:106] Iteration 77, lr = 0.01
I1026 00:29:51.147990 44939 solver.cpp:228] Iteration 78, loss = 6.90789
I1026 00:29:51.148036 44939 solver.cpp:244]     Train net output #0: loss = 6.90789 (* 1 = 6.90789 loss)
I1026 00:29:51.148043 44939 sgd_solver.cpp:106] Iteration 78, lr = 0.01
I1026 00:29:51.596179 44939 solver.cpp:228] Iteration 79, loss = 6.90791
I1026 00:29:51.596235 44939 solver.cpp:244]     Train net output #0: loss = 6.90791 (* 1 = 6.90791 loss)
I1026 00:29:51.596242 44939 sgd_solver.cpp:106] Iteration 79, lr = 0.01
I1026 00:29:51.596469 44939 solver.cpp:454] Snapshotting to binary proto file _iter_80.caffemodel
I1026 00:29:52.217353 44939 sgd_solver.cpp:273] Snapshotting solver state to binary proto file _iter_80.solverstate
I1026 00:29:52.536043 44939 solver.cpp:317] Iteration 80, loss = 6.90745
I1026 00:29:52.536085 44939 solver.cpp:322] Optimization Done.
I1026 00:29:52.536093 44939 caffe.cpp:254] Optimization Done.
