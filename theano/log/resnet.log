[global]
device = gpu
floatX = float32
optimizer_including = unsafe

[cuda]
root = /usr/local/cuda-7.5/

[lib]
cnmem = 0.45

[dnn.conv]
algo_fwd = time_once
algo_bwd_filter = time_once
algo_bwd_data = time_once
Using gpu device 0: GeForce GTX TITAN X (CNMeM is enabled with initial size: 45.0% of memory, cuDNN 5103)
Building model...
number of parameters in model: 25557096
Compiling theano functions...
Functions are compiled
2016-09-13 11:33:27.603306: step 10, duration = 0.123
2016-09-13 11:33:28.833192: step 20, duration = 0.123
2016-09-13 11:33:30.063762: step 30, duration = 0.123
2016-09-13 11:33:31.293204: step 40, duration = 0.123
2016-09-13 11:33:32.526004: step 50, duration = 0.124
2016-09-13 11:33:33.757625: step 60, duration = 0.123
2016-09-13 11:33:34.987836: step 70, duration = 0.123
2016-09-13 11:33:36.218471: step 80, duration = 0.123
2016-09-13 11:33:37.448346: step 90, duration = 0.123
2016-09-13 11:33:38.555932: Forward across 100 steps, 0.123 +/- 0.000 sec / batch
2016-09-13 11:33:54.585951: step 10, duration = 0.594
2016-09-13 11:34:00.549183: step 20, duration = 0.597
2016-09-13 11:34:06.524992: step 30, duration = 0.599
2016-09-13 11:34:12.533006: step 40, duration = 0.597
2016-09-13 11:34:18.496179: step 50, duration = 0.594
2016-09-13 11:34:24.475129: step 60, duration = 0.596
2016-09-13 11:34:30.446618: step 70, duration = 0.596
2016-09-13 11:34:36.424185: step 80, duration = 0.604
2016-09-13 11:34:42.392608: step 90, duration = 0.598
2016-09-13 11:34:47.771873: Forward-Backward across 100 steps, 0.597 +/- 0.003 sec / batch
[global]
device = gpu
floatX = float32
optimizer_including = unsafe

[cuda]
root = /usr/local/cuda-7.5/

[lib]
cnmem = 0.45

[dnn.conv]
algo_fwd = time_once
algo_bwd_filter = time_once
algo_bwd_data = time_once
Using gpu device 0: GeForce GTX TITAN X (CNMeM is enabled with initial size: 45.0% of memory, cuDNN 5103)
Building model...
number of parameters in model: 25557096
Compiling theano functions...
Functions are compiled
2016-09-14 16:34:53.330075: step 10, duration = 0.126
2016-09-14 16:34:54.583860: step 20, duration = 0.125
2016-09-14 16:34:55.832132: step 30, duration = 0.125
2016-09-14 16:34:57.080896: step 40, duration = 0.125
2016-09-14 16:34:58.328283: step 50, duration = 0.125
2016-09-14 16:34:59.576722: step 60, duration = 0.125
2016-09-14 16:35:00.823083: step 70, duration = 0.125
2016-09-14 16:35:02.070866: step 80, duration = 0.125
2016-09-14 16:35:03.319572: step 90, duration = 0.125
2016-09-14 16:35:04.445954: Forward across 100 steps, 0.125 +/- 0.000 sec / batch
2016-09-14 16:35:20.821568: step 10, duration = 0.696
2016-09-14 16:35:26.925290: step 20, duration = 0.608
2016-09-14 16:35:32.971333: step 30, duration = 0.606
2016-09-14 16:35:39.033733: step 40, duration = 0.603
2016-09-14 16:35:45.240358: step 50, duration = 0.647
2016-09-14 16:35:52.464623: step 60, duration = 0.723
2016-09-14 16:35:59.862474: step 70, duration = 0.728
2016-09-14 16:36:06.218606: step 80, duration = 0.597
2016-09-14 16:36:12.174815: step 90, duration = 0.595
2016-09-14 16:36:17.533236: Forward-Backward across 100 steps, 0.644 +/- 0.058 sec / batch
