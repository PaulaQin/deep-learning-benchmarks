[global]
device = gpu
floatX = float32
optimizer_including = unsafe

[cuda]
root = /usr/local/cuda-7.5/

[lib]
cnmem = 0.45

[dnn.conv]
algo_fwd = time_once
algo_bwd_filter = time_once
algo_bwd_data = time_once
Using gpu device 0: GeForce GTX TITAN X (CNMeM is enabled with initial size: 45.0% of memory, cuDNN 5103)
Building model...
number of parameters in model: 6182160
Compiling theano functions...
Functions are compiled
2016-09-14 16:06:30.445125: step 10, duration = 0.009
2016-09-14 16:06:30.548227: step 20, duration = 0.009
2016-09-14 16:06:30.638269: step 30, duration = 0.008
2016-09-14 16:06:30.720921: step 40, duration = 0.008
2016-09-14 16:06:30.803320: step 50, duration = 0.008
2016-09-14 16:06:30.886104: step 60, duration = 0.008
2016-09-14 16:06:30.968482: step 70, duration = 0.008
2016-09-14 16:06:31.050925: step 80, duration = 0.008
2016-09-14 16:06:31.133631: step 90, duration = 0.008
2016-09-14 16:06:31.208667: Forward across 100 steps, 0.009 +/- 0.001 sec / batch
2016-09-14 16:06:32.092040: step 10, duration = 0.042
2016-09-14 16:06:32.512969: step 20, duration = 0.042
2016-09-14 16:06:32.934149: step 30, duration = 0.042
2016-09-14 16:06:33.355093: step 40, duration = 0.042
2016-09-14 16:06:33.776035: step 50, duration = 0.042
2016-09-14 16:06:34.196434: step 60, duration = 0.042
2016-09-14 16:06:34.617566: step 70, duration = 0.042
2016-09-14 16:06:35.038096: step 80, duration = 0.042
2016-09-14 16:06:35.459200: step 90, duration = 0.042
2016-09-14 16:06:35.837602: Forward-Backward across 100 steps, 0.042 +/- 0.000 sec / batch
[global]
device = gpu
floatX = float32
optimizer_including = unsafe

[cuda]
root = /usr/local/cuda-7.5/

[lib]
cnmem = 0.45

[dnn.conv]
algo_fwd = time_once
algo_bwd_filter = time_once
algo_bwd_data = time_once
Using gpu device 0: GeForce GTX TITAN X (CNMeM is enabled with initial size: 45.0% of memory, cuDNN 5103)
Building model...
number of parameters in model: 6182160
Compiling theano functions...
Functions are compiled
2016-09-14 16:40:56.502143: step 10, duration = 0.009
2016-09-14 16:40:56.590829: step 20, duration = 0.009
2016-09-14 16:40:56.675224: step 30, duration = 0.008
2016-09-14 16:40:56.758828: step 40, duration = 0.008
2016-09-14 16:40:56.842938: step 50, duration = 0.008
2016-09-14 16:40:56.927114: step 60, duration = 0.008
2016-09-14 16:40:57.011336: step 70, duration = 0.008
2016-09-14 16:40:57.095488: step 80, duration = 0.008
2016-09-14 16:40:57.179024: step 90, duration = 0.008
2016-09-14 16:40:57.252617: Forward across 100 steps, 0.008 +/- 0.000 sec / batch
2016-09-14 16:40:58.132807: step 10, duration = 0.042
2016-09-14 16:40:58.552027: step 20, duration = 0.042
2016-09-14 16:40:58.971421: step 30, duration = 0.042
2016-09-14 16:40:59.390650: step 40, duration = 0.042
2016-09-14 16:40:59.810050: step 50, duration = 0.042
2016-09-14 16:41:00.229205: step 60, duration = 0.042
2016-09-14 16:41:00.648731: step 70, duration = 0.042
2016-09-14 16:41:01.068025: step 80, duration = 0.042
2016-09-14 16:41:01.487231: step 90, duration = 0.042
2016-09-14 16:41:01.864407: Forward-Backward across 100 steps, 0.042 +/- 0.000 sec / batch
