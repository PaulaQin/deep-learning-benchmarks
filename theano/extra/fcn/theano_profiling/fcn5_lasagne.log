Using gpu device 1: GeForce GTX TITAN X (CNMeM is enabled with initial size: 45.0% of memory, cuDNN 5103)
/usr/local/lib/python2.7/dist-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.
  warnings.warn(warn)
Function profiling
==================
  Message: ../../benchmark.py:96
  Time in 0 calls to Function.__call__: 0.000000e+00s
  Total compile time: 6.800699e-02s
    Number of Apply nodes: 14
    Theano Optimizer time: 4.088187e-02s
       Theano validate time: 1.074076e-03s
    Theano Linker time (includes C, CUDA code generation/compiling): 1.350021e-02s
       Import time 8.611679e-04s

Time in all call to theano.grad() 1.714087e-02s
Time since theano import 13.703s
Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: ../../benchmark.py:97
  Time in 200 calls to Function.__call__: 3.102892e+00s
  Time in Function.fn.__call__: 3.094573e+00s (99.732%)
  Time in thunks: 3.087985e+00s (99.520%)
  Total compile time: 3.444581e-01s
    Number of Apply nodes: 48
    Theano Optimizer time: 2.785451e-01s
       Theano validate time: 1.187921e-02s
    Theano Linker time (includes C, CUDA code generation/compiling): 4.919791e-02s
       Import time 2.423525e-03s

Time in all call to theano.grad() 1.714087e-02s
Time since theano import 13.703s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  62.8%    62.8%       1.938s       1.38e-03s     C     1400       7   theano.sandbox.cuda.blas.GpuDot22
  28.2%    91.0%       0.872s       1.09e-03s     C      800       4   theano.sandbox.cuda.blas.GpuGemm
   4.8%    95.8%       0.147s       2.45e-04s     C      600       3   theano.sandbox.cuda.basic_ops.GpuFromHost
   1.4%    97.2%       0.044s       1.83e-05s     C     2400      12   theano.sandbox.cuda.basic_ops.GpuElemwise
   1.3%    98.5%       0.040s       2.01e-04s     C      200       1   theano.sandbox.cuda.nnet.GpuCrossentropySoftmaxArgmax1HotWithBias
   0.8%    99.3%       0.024s       2.36e-05s     C     1000       5   theano.sandbox.cuda.basic_ops.GpuCAReduce
   0.6%    99.9%       0.019s       9.27e-05s     C      200       1   theano.sandbox.cuda.nnet.GpuCrossentropySoftmax1HotWithBiasDx
   0.1%    99.9%       0.003s       1.29e-05s     C      200       1   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       0.001s       5.45e-07s     C     2200      11   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.0%   100.0%       0.001s       1.45e-06s     C      400       2   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.000s       8.80e-07s     C      200       1   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  62.8%    62.8%       1.938s       1.38e-03s     C     1400        7   GpuDot22
  28.2%    91.0%       0.872s       1.09e-03s     C      800        4   GpuGemm{inplace}
   4.8%    95.8%       0.147s       2.45e-04s     C      600        3   GpuFromHost
   1.3%    97.1%       0.040s       2.01e-04s     C      200        1   GpuCrossentropySoftmaxArgmax1HotWithBias
   0.7%    97.7%       0.021s       2.60e-05s     C      800        4   GpuCAReduce{add}{1,0}
   0.6%    98.3%       0.019s       9.27e-05s     C      200        1   GpuCrossentropySoftmax1HotWithBiasDx
   0.5%    98.9%       0.017s       2.83e-05s     C      600        3   GpuElemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)]
   0.4%    99.3%       0.012s       1.94e-05s     C      600        3   GpuElemwise{Composite{((i0 * i1) * (i2 - i1))}}[(0, 0)]
   0.3%    99.6%       0.010s       1.26e-05s     C      800        4   GpuElemwise{Composite{(i0 - (i1 * i2))}}[(0, 0)]
   0.1%    99.7%       0.003s       1.40e-05s     C      200        1   GpuCAReduce{add}{1}
   0.1%    99.8%       0.003s       1.36e-05s     C      200        1   GpuElemwise{Inv}[(0, 0)]
   0.1%    99.9%       0.003s       1.31e-05s     C      200        1   GpuElemwise{TrueDiv}[(0, 0)]
   0.1%    99.9%       0.003s       1.29e-05s     C      200        1   HostFromGpu
   0.0%   100.0%       0.001s       4.75e-07s     C     1400        7   GpuDimShuffle{1,0}
   0.0%   100.0%       0.000s       2.21e-06s     C      200        1   Elemwise{Identity}
   0.0%   100.0%       0.000s       6.93e-07s     C      600        3   GpuDimShuffle{x,0}
   0.0%   100.0%       0.000s       8.80e-07s     C      200        1   Shape_i{0}
   0.0%   100.0%       0.000s       6.87e-07s     C      200        1   Elemwise{Cast{float32}}
   0.0%   100.0%       0.000s       5.89e-07s     C      200        1   GpuDimShuffle{x}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  26.3%    26.3%       0.812s       4.06e-03s    200    31   GpuDot22(GpuCrossentropySoftmax1HotWithBiasDx.0, GpuDimShuffle{1,0}.0)
  21.1%    47.4%       0.650s       3.25e-03s    200    10   GpuDot22(GpuFromHost.0, W)
  14.3%    61.6%       0.441s       2.20e-03s    200    32   GpuGemm{inplace}(W, TensorConstant{-0.10000000149}, GpuDimShuffle{1,0}.0, GpuCrossentropySoftmax1HotWithBiasDx.0, TensorConstant{1.0})
  11.7%    73.3%       0.360s       1.80e-03s    200    46   GpuGemm{inplace}(W, TensorConstant{-0.10000000149}, GpuDimShuffle{1,0}.0, GpuElemwise{Composite{((i0 * i1) * (i2 - i1))}}[(0, 0)].0, TensorConstant{1.0})
   8.5%    81.8%       0.263s       1.31e-03s    200    22   GpuDot22(GpuElemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)].0, W)
   4.6%    86.4%       0.143s       7.15e-04s    200     7   GpuFromHost(input)
   1.9%    88.4%       0.060s       2.99e-04s    200    41   GpuDot22(GpuElemwise{Composite{((i0 * i1) * (i2 - i1))}}[(0, 0)].0, GpuDimShuffle{1,0}.0)
   1.7%    90.1%       0.052s       2.60e-04s    200    36   GpuDot22(GpuElemwise{Composite{((i0 * i1) * (i2 - i1))}}[(0, 0)].0, GpuDimShuffle{1,0}.0)
   1.7%    91.7%       0.051s       2.55e-04s    200    19   GpuDot22(GpuElemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)].0, W)
   1.6%    93.3%       0.050s       2.48e-04s    200    15   GpuDot22(GpuElemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)].0, W)
   1.3%    94.6%       0.040s       2.01e-04s    200    24   GpuCrossentropySoftmaxArgmax1HotWithBias(GpuDot22.0, b, GpuFromHost.0)
   1.2%    95.8%       0.036s       1.79e-04s    200    37   GpuGemm{inplace}(W, TensorConstant{-0.10000000149}, GpuDimShuffle{1,0}.0, GpuElemwise{Composite{((i0 * i1) * (i2 - i1))}}[(0, 0)].0, TensorConstant{1.0})
   1.2%    96.9%       0.036s       1.78e-04s    200    42   GpuGemm{inplace}(W, TensorConstant{-0.10000000149}, GpuDimShuffle{1,0}.0, GpuElemwise{Composite{((i0 * i1) * (i2 - i1))}}[(0, 0)].0, TensorConstant{1.0})
   0.6%    97.5%       0.019s       9.27e-05s    200    29   GpuCrossentropySoftmax1HotWithBiasDx(GpuElemwise{Inv}[(0, 0)].0, GpuCrossentropySoftmaxArgmax1HotWithBias.1, GpuFromHost.0)
   0.3%    97.8%       0.009s       4.40e-05s    200    30   GpuCAReduce{add}{1,0}(GpuCrossentropySoftmax1HotWithBiasDx.0)
   0.2%    98.0%       0.006s       3.05e-05s    200    13   GpuElemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)](GpuDot22.0, GpuDimShuffle{x,0}.0)
   0.2%    98.2%       0.005s       2.72e-05s    200    18   GpuElemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)](GpuDot22.0, GpuDimShuffle{x,0}.0)
   0.2%    98.4%       0.005s       2.71e-05s    200    21   GpuElemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)](GpuDot22.0, GpuDimShuffle{x,0}.0)
   0.1%    98.5%       0.004s       2.11e-05s    200    34   GpuElemwise{Composite{((i0 * i1) * (i2 - i1))}}[(0, 0)](GpuDot22.0, GpuElemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)].0, CudaNdarrayConstant{[[ 1.]]})
   0.1%    98.6%       0.004s       2.08e-05s    200    45   GpuCAReduce{add}{1,0}(GpuElemwise{Composite{((i0 * i1) * (i2 - i1))}}[(0, 0)].0)
   ... (remaining 28 Apply instances account for 1.36%(0.04s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Function profiling
==================
  Message: Sum of all(2) printed profiles at exit excluding Scan op profile.
  Time in 200 calls to Function.__call__: 3.102892e+00s
  Time in Function.fn.__call__: 3.094573e+00s (99.732%)
  Time in thunks: 3.087985e+00s (99.520%)
  Total compile time: 4.124651e-01s
    Number of Apply nodes: 14
    Theano Optimizer time: 3.194270e-01s
       Theano validate time: 1.295328e-02s
    Theano Linker time (includes C, CUDA code generation/compiling): 6.269813e-02s
       Import time 3.284693e-03s

Time in all call to theano.grad() 1.714087e-02s
Time since theano import 13.706s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  62.8%    62.8%       1.938s       1.38e-03s     C     1400       7   theano.sandbox.cuda.blas.GpuDot22
  28.2%    91.0%       0.872s       1.09e-03s     C      800       4   theano.sandbox.cuda.blas.GpuGemm
   4.8%    95.8%       0.147s       2.45e-04s     C      600       3   theano.sandbox.cuda.basic_ops.GpuFromHost
   1.4%    97.2%       0.044s       1.83e-05s     C     2400      12   theano.sandbox.cuda.basic_ops.GpuElemwise
   1.3%    98.5%       0.040s       2.01e-04s     C      200       1   theano.sandbox.cuda.nnet.GpuCrossentropySoftmaxArgmax1HotWithBias
   0.8%    99.3%       0.024s       2.36e-05s     C     1000       5   theano.sandbox.cuda.basic_ops.GpuCAReduce
   0.6%    99.9%       0.019s       9.27e-05s     C      200       1   theano.sandbox.cuda.nnet.GpuCrossentropySoftmax1HotWithBiasDx
   0.1%    99.9%       0.003s       1.29e-05s     C      200       1   theano.sandbox.cuda.basic_ops.HostFromGpu
   0.0%   100.0%       0.001s       5.45e-07s     C     2200      11   theano.sandbox.cuda.basic_ops.GpuDimShuffle
   0.0%   100.0%       0.001s       1.45e-06s     C      400       2   theano.tensor.elemwise.Elemwise
   0.0%   100.0%       0.000s       8.80e-07s     C      200       1   theano.compile.ops.Shape_i
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  62.8%    62.8%       1.938s       1.38e-03s     C     1400        7   GpuDot22
  28.2%    91.0%       0.872s       1.09e-03s     C      800        4   GpuGemm{inplace}
   4.8%    95.8%       0.147s       2.45e-04s     C      600        3   GpuFromHost
   1.3%    97.1%       0.040s       2.01e-04s     C      200        1   GpuCrossentropySoftmaxArgmax1HotWithBias
   0.7%    97.7%       0.021s       2.60e-05s     C      800        4   GpuCAReduce{add}{1,0}
   0.6%    98.3%       0.019s       9.27e-05s     C      200        1   GpuCrossentropySoftmax1HotWithBiasDx
   0.5%    98.9%       0.017s       2.83e-05s     C      600        3   GpuElemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)]
   0.4%    99.3%       0.012s       1.94e-05s     C      600        3   GpuElemwise{Composite{((i0 * i1) * (i2 - i1))}}[(0, 0)]
   0.3%    99.6%       0.010s       1.26e-05s     C      800        4   GpuElemwise{Composite{(i0 - (i1 * i2))}}[(0, 0)]
   0.1%    99.7%       0.003s       1.40e-05s     C      200        1   GpuCAReduce{add}{1}
   0.1%    99.8%       0.003s       1.36e-05s     C      200        1   GpuElemwise{Inv}[(0, 0)]
   0.1%    99.9%       0.003s       1.31e-05s     C      200        1   GpuElemwise{TrueDiv}[(0, 0)]
   0.1%    99.9%       0.003s       1.29e-05s     C      200        1   HostFromGpu
   0.0%   100.0%       0.001s       4.75e-07s     C     1400        7   GpuDimShuffle{1,0}
   0.0%   100.0%       0.000s       2.21e-06s     C      200        1   Elemwise{Identity}
   0.0%   100.0%       0.000s       6.93e-07s     C      600        3   GpuDimShuffle{x,0}
   0.0%   100.0%       0.000s       8.80e-07s     C      200        1   Shape_i{0}
   0.0%   100.0%       0.000s       6.87e-07s     C      200        1   Elemwise{Cast{float32}}
   0.0%   100.0%       0.000s       5.89e-07s     C      200        1   GpuDimShuffle{x}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  26.3%    26.3%       0.812s       4.06e-03s    200    31   GpuDot22(GpuCrossentropySoftmax1HotWithBiasDx.0, GpuDimShuffle{1,0}.0)
  21.1%    47.4%       0.650s       3.25e-03s    200    10   GpuDot22(GpuFromHost.0, W)
  14.3%    61.6%       0.441s       2.20e-03s    200    32   GpuGemm{inplace}(W, TensorConstant{-0.10000000149}, GpuDimShuffle{1,0}.0, GpuCrossentropySoftmax1HotWithBiasDx.0, TensorConstant{1.0})
  11.7%    73.3%       0.360s       1.80e-03s    200    46   GpuGemm{inplace}(W, TensorConstant{-0.10000000149}, GpuDimShuffle{1,0}.0, GpuElemwise{Composite{((i0 * i1) * (i2 - i1))}}[(0, 0)].0, TensorConstant{1.0})
   8.5%    81.8%       0.263s       1.31e-03s    200    22   GpuDot22(GpuElemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)].0, W)
   4.6%    86.4%       0.143s       7.15e-04s    200     7   GpuFromHost(input)
   1.9%    88.4%       0.060s       2.99e-04s    200    41   GpuDot22(GpuElemwise{Composite{((i0 * i1) * (i2 - i1))}}[(0, 0)].0, GpuDimShuffle{1,0}.0)
   1.7%    90.1%       0.052s       2.60e-04s    200    36   GpuDot22(GpuElemwise{Composite{((i0 * i1) * (i2 - i1))}}[(0, 0)].0, GpuDimShuffle{1,0}.0)
   1.7%    91.7%       0.051s       2.55e-04s    200    19   GpuDot22(GpuElemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)].0, W)
   1.6%    93.3%       0.050s       2.48e-04s    200    15   GpuDot22(GpuElemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)].0, W)
   1.3%    94.6%       0.040s       2.01e-04s    200    24   GpuCrossentropySoftmaxArgmax1HotWithBias(GpuDot22.0, b, GpuFromHost.0)
   1.2%    95.8%       0.036s       1.79e-04s    200    37   GpuGemm{inplace}(W, TensorConstant{-0.10000000149}, GpuDimShuffle{1,0}.0, GpuElemwise{Composite{((i0 * i1) * (i2 - i1))}}[(0, 0)].0, TensorConstant{1.0})
   1.2%    96.9%       0.036s       1.78e-04s    200    42   GpuGemm{inplace}(W, TensorConstant{-0.10000000149}, GpuDimShuffle{1,0}.0, GpuElemwise{Composite{((i0 * i1) * (i2 - i1))}}[(0, 0)].0, TensorConstant{1.0})
   0.6%    97.5%       0.019s       9.27e-05s    200    29   GpuCrossentropySoftmax1HotWithBiasDx(GpuElemwise{Inv}[(0, 0)].0, GpuCrossentropySoftmaxArgmax1HotWithBias.1, GpuFromHost.0)
   0.3%    97.8%       0.009s       4.40e-05s    200    30   GpuCAReduce{add}{1,0}(GpuCrossentropySoftmax1HotWithBiasDx.0)
   0.2%    98.0%       0.006s       3.05e-05s    200    13   GpuElemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)](GpuDot22.0, GpuDimShuffle{x,0}.0)
   0.2%    98.2%       0.005s       2.72e-05s    200    18   GpuElemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)](GpuDot22.0, GpuDimShuffle{x,0}.0)
   0.2%    98.4%       0.005s       2.71e-05s    200    21   GpuElemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)](GpuDot22.0, GpuDimShuffle{x,0}.0)
   0.1%    98.5%       0.004s       2.11e-05s    200    34   GpuElemwise{Composite{((i0 * i1) * (i2 - i1))}}[(0, 0)](GpuDot22.0, GpuElemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)].0, CudaNdarrayConstant{[[ 1.]]})
   0.1%    98.6%       0.004s       2.08e-05s    200    45   GpuCAReduce{add}{1,0}(GpuElemwise{Composite{((i0 * i1) * (i2 - i1))}}[(0, 0)].0)
   ... (remaining 28 Apply instances account for 1.36%(0.04s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  Sorry, no tip for today.
Building model...
number of parameters in model: 117997696
Compiling theano functions...
Functions are compiled
('input_size:', (64, 26752))
2016-09-30 16:24:20.523158: step 10, duration = 0.016
2016-09-30 16:24:20.679072: step 20, duration = 0.015
2016-09-30 16:24:20.835120: step 30, duration = 0.016
2016-09-30 16:24:20.991465: step 40, duration = 0.016
2016-09-30 16:24:21.147435: step 50, duration = 0.016
2016-09-30 16:24:21.303289: step 60, duration = 0.016
2016-09-30 16:24:21.459187: step 70, duration = 0.016
2016-09-30 16:24:21.615015: step 80, duration = 0.016
2016-09-30 16:24:21.770855: step 90, duration = 0.016
2016-09-30 16:24:21.926656: step 100, duration = 0.016
2016-09-30 16:24:22.082128: step 110, duration = 0.016
2016-09-30 16:24:22.238191: step 120, duration = 0.016
2016-09-30 16:24:22.393880: step 130, duration = 0.016
2016-09-30 16:24:22.549862: step 140, duration = 0.016
2016-09-30 16:24:22.705844: step 150, duration = 0.016
2016-09-30 16:24:22.861833: step 160, duration = 0.016
2016-09-30 16:24:23.017540: step 170, duration = 0.016
2016-09-30 16:24:23.173509: step 180, duration = 0.016
2016-09-30 16:24:23.313899: Forward-Backward across 190 steps, 0.016 +/- 0.000 sec / batch
