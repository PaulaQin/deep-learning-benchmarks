-------------------------------------------------------------------
Build info: 

		Built time: Sep 27 2016 14:05:01
		Last modified date: Tue Sep 27 07:19:56 2016
		Build type: release
		Build target: GPU
		With 1bit-SGD: yes
		Math lib: mkl
		CUDA_PATH: /usr/local/cuda-7.5
		CUB_PATH: /usr/local/cub-1.4.1
		CUDNN_PATH: /usr/local/cudnn-5.1
		Build Branch: HEAD
		Build SHA1: 2e4a773398b5ee84e1695abe73eb831c3cca1e36
		Built by philly on 9ab719fcc26d
		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux
-------------------------------------------------------------------
-------------------------------------------------------------------
GPU info:

		Device[0]: cores = 4608; computeCapability = 5.2; type = "GeForce GTX TITAN X"; memory = 12205 MB
		Device[1]: cores = 4608; computeCapability = 5.2; type = "GeForce GTX TITAN X"; memory = 12206 MB
		Device[2]: cores = 4608; computeCapability = 5.2; type = "GeForce GTX TITAN X"; memory = 12206 MB
		Device[3]: cores = 4608; computeCapability = 5.2; type = "GeForce GTX TITAN X"; memory = 12206 MB
-------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: alexnet.cntk:command=Train
configparameters: alexnet.cntk:ConfigDir=cnn/alexnet
configparameters: alexnet.cntk:configName=alexnet
configparameters: alexnet.cntk:DataDir=cnn
configparameters: alexnet.cntk:deviceId=0
configparameters: alexnet.cntk:epochSize=640
configparameters: alexnet.cntk:imageLayout=cudnn
configparameters: alexnet.cntk:initOnCPUOnly=true
configparameters: alexnet.cntk:makeMode=false
configparameters: alexnet.cntk:maxEpochs=2
configparameters: alexnet.cntk:minibatchSize=16
configparameters: alexnet.cntk:ModelDir=./Output/alexnet
configparameters: alexnet.cntk:ndlMacros=cnn/alexnet/Macros.ndl
configparameters: alexnet.cntk:parallelTrain=false
configparameters: alexnet.cntk:precision=float
configparameters: alexnet.cntk:prefetch=true
configparameters: alexnet.cntk:stderr=./output_alexnet_Train.log
configparameters: alexnet.cntk:traceLevel=1
configparameters: alexnet.cntk:Train=[
    action=train
    modelPath=./Output/alexnet/AlexNet
    deviceId=Auto
    NDLNetworkBuilder=[
        networkDescription=cnn/alexnet/AlexNet.ndl
    ]
    SGD=[
        epochSize=640
        minibatchSize=16
        maxEpochs=2
        learningRatesPerMB=0.01
        momentumPerMB=0
        dropoutRate=0
	    numMBsToShowResult=1
        ParallelTrain=[
            parallelizationMethod="DataParallelSGD"
            distributedMBReading="true"
            parallelizationStartEpoch=1
            DataParallelSGD=[
                gradientBits=1
            ]
        ]
    ]
    reader=[
        readerType=UCIFastReader
        file=cnn/imagenet_data.txt
        randomize=None
        features=[
            dim=150528
            start=1
        ]
        labels=[
            dim=1
            start=0
            labelDim=1000
            labelMappingFile=cnn/labelmap.1K.txt
        ]
    ]
]

configparameters: alexnet.cntk:WorkDir=.
Commands: Train
precision = "float"

##############################################################################
#                                                                            #
# Train command (train action)                                               #
#                                                                            #
##############################################################################

parallelTrain option is not enabled. ParallelTrain config will be ignored.

Creating virgin network.
NDLBuilder Using GPU 1

h1.t Times operation: For legacy compatibility, the sample layout of left input (h1.W LearnableParameter operation) was patched to [4096 x 6 x 6 x 256] (from [4096 x 9216])
conv1_act.conv: using cuDNN convolution engine for geometry: Input: 224 x 224 x 3, Output: 56 x 56 x 96, Kernel: 11 x 11 x 3, Map: 1 x 1 x 96, Stride: 4 x 4 x 3, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.
pool1: using cuDNN convolution engine for geometry: Input: 56 x 56 x 96, Output: 27 x 27 x 96, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.
conv2_act.conv: using cuDNN convolution engine for geometry: Input: 27 x 27 x 96, Output: 27 x 27 x 256, Kernel: 5 x 5 x 96, Map: 1 x 1 x 256, Stride: 1 x 1 x 96, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.
pool2: using cuDNN convolution engine for geometry: Input: 27 x 27 x 256, Output: 13 x 13 x 256, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.
conv3_act.conv: using cuDNN convolution engine for geometry: Input: 13 x 13 x 256, Output: 13 x 13 x 384, Kernel: 3 x 3 x 256, Map: 1 x 1 x 384, Stride: 1 x 1 x 256, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.
conv4_act.conv: using cuDNN convolution engine for geometry: Input: 13 x 13 x 384, Output: 13 x 13 x 384, Kernel: 3 x 3 x 384, Map: 1 x 1 x 384, Stride: 1 x 1 x 384, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.
conv5_act.conv: using cuDNN convolution engine for geometry: Input: 13 x 13 x 384, Output: 13 x 13 x 256, Kernel: 3 x 3 x 384, Map: 1 x 1 x 256, Stride: 1 x 1 x 384, Sharing: (1), AutoPad: (1), LowerPad: 0, UpperPad: 0.
pool3: using cuDNN convolution engine for geometry: Input: 13 x 13 x 256, Output: 6 x 6 x 256, Kernel: 3 x 3 x 1, Map: 1, Stride: 2 x 2 x 1, Sharing: (1), AutoPad: (0), LowerPad: 0, UpperPad: 0.
********** DEPRECATED **********
UCIFastReader is no longer actively maintained.
It is known to have defects, proceed with caution (better yet, switch to CNTKTextFormatReader)!
For more details please see https://github.com/Microsoft/CNTK/wiki 
Reading UCI file cnn/imagenet_data.txt

Model has 46 nodes. Using GPU 1.

Training criterion:   CE = CrossEntropyWithSoftmax
Evaluation criterion: Err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 89 matrices, 60 are shared as 26, and 29 are not shared.

	{ conv1_act.convPlusB : [56 x 56 x 96 x *]
	  conv1_act.convW : [96 x 363] (gradient) }
	{ conv1_act.convPlusB : [56 x 56 x 96 x *] (gradient)
	  pool1 : [27 x 27 x 96 x *] }
	{ conv1_act.act : [56 x 56 x 96 x *] (gradient)
	  conv1_act.convB : [1 x 1 x 96] (gradient) }
	{ conv2_act.convPlusB : [27 x 27 x 256 x *]
	  conv2_act.convW : [256 x 2400] (gradient) }
	{ conv2_act.act : [27 x 27 x 256 x *]
	  conv2_act.conv : [27 x 27 x 256 x *] (gradient) }
	{ conv2_act.convPlusB : [27 x 27 x 256 x *] (gradient)
	  pool1 : [27 x 27 x 96 x *] (gradient)
	  pool2 : [13 x 13 x 256 x *] }
	{ conv2_act.act : [27 x 27 x 256 x *] (gradient)
	  conv2_act.convB : [1 x 1 x 256] (gradient) }
	{ conv3_act.convPlusB : [13 x 13 x 384 x *]
	  conv3_act.convW : [384 x 2304] (gradient) }
	{ conv3_act.act : [13 x 13 x 384 x *]
	  conv3_act.conv : [13 x 13 x 384 x *] (gradient) }
	{ conv3_act.convPlusB : [13 x 13 x 384 x *] (gradient)
	  pool2 : [13 x 13 x 256 x *] (gradient) }
	{ conv4_act.convPlusB : [13 x 13 x 384 x *]
	  conv4_act.convW : [384 x 3456] (gradient) }
	{ conv1_act.act : [56 x 56 x 96 x *]
	  conv1_act.conv : [56 x 56 x 96 x *] (gradient) }
	{ conv4_act.act : [13 x 13 x 384 x *]
	  conv4_act.conv : [13 x 13 x 384 x *] (gradient) }
	{ conv3_act.act : [13 x 13 x 384 x *] (gradient)
	  conv3_act.convB : [1 x 1 x 384] (gradient)
	  conv4_act.convPlusB : [13 x 13 x 384 x *] (gradient) }
	{ conv5_act.convPlusB : [13 x 13 x 256 x *]
	  conv5_act.convW : [256 x 3456] (gradient) }
	{ conv5_act.act : [13 x 13 x 256 x *]
	  conv5_act.conv : [13 x 13 x 256 x *] (gradient) }
	{ conv4_act.act : [13 x 13 x 384 x *] (gradient)
	  conv4_act.convB : [1 x 1 x 384] (gradient)
	  conv5_act.convPlusB : [13 x 13 x 256 x *] (gradient)
	  pool3 : [6 x 6 x 256 x *] }
	{ conv5_act.act : [13 x 13 x 256 x *] (gradient)
	  conv5_act.convB : [1 x 1 x 256] (gradient)
	  h1.t : [4096 x *] }
	{ h1.W : [4096 x 6 x 6 x 256] (gradient)
	  h1.z : [4096 x *] }
	{ h1.t : [4096 x *] (gradient)
	  h1.y : [4096 x *] }
	{ h1.z : [4096 x *] (gradient)
	  h2.t : [4096 x *]
	  pool3 : [6 x 6 x 256 x *] (gradient) }
	{ h2.W : [4096 x 4096] (gradient)
	  h2.z : [4096 x *] }
	{ h2.t : [4096 x *] (gradient)
	  h2.y : [4096 x *] }
	{ OutputNodes.t : [1000 x *]
	  h1.b : [4096] (gradient)
	  h1.y : [4096 x *] (gradient)
	  h2.z : [4096 x *] (gradient) }
	{ OutputNodes.W : [1000 x 4096] (gradient)
	  OutputNodes.z : [1000 x *] (gradient) }
	{ h2.b : [4096] (gradient)
	  h2.y : [4096 x *] (gradient) }


Training 62378344 parameters in 16 out of 16 parameter tensors and 43 nodes with gradient:

	Node 'OutputNodes.W' (LearnableParameter operation) : [1000 x 4096]
	Node 'OutputNodes.b' (LearnableParameter operation) : [1000]
	Node 'conv1_act.convB' (LearnableParameter operation) : [1 x 1 x 96]
	Node 'conv1_act.convW' (LearnableParameter operation) : [96 x 363]
	Node 'conv2_act.convB' (LearnableParameter operation) : [1 x 1 x 256]
	Node 'conv2_act.convW' (LearnableParameter operation) : [256 x 2400]
	Node 'conv3_act.convB' (LearnableParameter operation) : [1 x 1 x 384]
	Node 'conv3_act.convW' (LearnableParameter operation) : [384 x 2304]
	Node 'conv4_act.convB' (LearnableParameter operation) : [1 x 1 x 384]
	Node 'conv4_act.convW' (LearnableParameter operation) : [384 x 3456]
	Node 'conv5_act.convB' (LearnableParameter operation) : [1 x 1 x 256]
	Node 'conv5_act.convW' (LearnableParameter operation) : [256 x 3456]
	Node 'h1.W' (LearnableParameter operation) : [4096 x 6 x 6 x 256]
	Node 'h1.b' (LearnableParameter operation) : [4096]
	Node 'h2.W' (LearnableParameter operation) : [4096 x 4096]
	Node 'h2.b' (LearnableParameter operation) : [4096]

No PreCompute nodes found, or all already computed. Skipping pre-computation step.

Starting Epoch 1: learning rate per sample = 0.000625  effective momentum = 0.000000  momentum as time constant = 0.0 samples
UCIFastReader: Starting at epoch 0, counting lines to determine record count...
 640 records found.
starting epoch 1 at record count 0, and file position 0
already there from last epoch

Starting minibatch loop.
 Epoch[ 1 of 2]-Minibatch[   1-   1, 2.50%]: CE = 7.08363485 * 16; Err = 1.00000000 * 16; time = 0.6495s; samplesPerSecond = 24.6
 Epoch[ 1 of 2]-Minibatch[   2-   2, 5.00%]: CE = 11.98561716 * 16; Err = 1.00000000 * 16; time = 0.0358s; samplesPerSecond = 447.2
 Epoch[ 1 of 2]-Minibatch[   3-   3, 7.50%]: CE = 10.13915253 * 16; Err = 1.00000000 * 16; time = 0.2258s; samplesPerSecond = 70.9
 Epoch[ 1 of 2]-Minibatch[   4-   4, 10.00%]: CE = 8.12680817 * 16; Err = 1.00000000 * 16; time = 0.2212s; samplesPerSecond = 72.3
 Epoch[ 1 of 2]-Minibatch[   5-   5, 12.50%]: CE = 7.82600784 * 16; Err = 1.00000000 * 16; time = 0.2143s; samplesPerSecond = 74.7
 Epoch[ 1 of 2]-Minibatch[   6-   6, 15.00%]: CE = 9.35137558 * 16; Err = 1.00000000 * 16; time = 0.1570s; samplesPerSecond = 101.9
 Epoch[ 1 of 2]-Minibatch[   7-   7, 17.50%]: CE = 7.51892853 * 16; Err = 1.00000000 * 16; time = 0.1576s; samplesPerSecond = 101.5
 Epoch[ 1 of 2]-Minibatch[   8-   8, 20.00%]: CE = 8.20082855 * 16; Err = 1.00000000 * 16; time = 0.1520s; samplesPerSecond = 105.3
 Epoch[ 1 of 2]-Minibatch[   9-   9, 22.50%]: CE = 7.53601837 * 16; Err = 1.00000000 * 16; time = 0.1356s; samplesPerSecond = 118.0
 Epoch[ 1 of 2]-Minibatch[  10-  10, 25.00%]: CE = 7.70812225 * 16; Err = 1.00000000 * 16; time = 0.1358s; samplesPerSecond = 117.8
 Epoch[ 1 of 2]-Minibatch[  11-  11, 27.50%]: CE = 7.50083160 * 16; Err = 1.00000000 * 16; time = 0.1350s; samplesPerSecond = 118.5
 Epoch[ 1 of 2]-Minibatch[  12-  12, 30.00%]: CE = 7.71731567 * 16; Err = 1.00000000 * 16; time = 0.1348s; samplesPerSecond = 118.7
 Epoch[ 1 of 2]-Minibatch[  13-  13, 32.50%]: CE = 7.72395325 * 16; Err = 1.00000000 * 16; time = 0.1347s; samplesPerSecond = 118.8
 Epoch[ 1 of 2]-Minibatch[  14-  14, 35.00%]: CE = 7.71584320 * 16; Err = 1.00000000 * 16; time = 0.1345s; samplesPerSecond = 119.0
 Epoch[ 1 of 2]-Minibatch[  15-  15, 37.50%]: CE = 7.39448547 * 16; Err = 1.00000000 * 16; time = 0.1350s; samplesPerSecond = 118.5
 Epoch[ 1 of 2]-Minibatch[  16-  16, 40.00%]: CE = 7.70053864 * 16; Err = 1.00000000 * 16; time = 0.1347s; samplesPerSecond = 118.8
 Epoch[ 1 of 2]-Minibatch[  17-  17, 42.50%]: CE = 7.30056763 * 16; Err = 1.00000000 * 16; time = 0.1347s; samplesPerSecond = 118.8
 Epoch[ 1 of 2]-Minibatch[  18-  18, 45.00%]: CE = 7.59199524 * 16; Err = 1.00000000 * 16; time = 0.1345s; samplesPerSecond = 119.0
 Epoch[ 1 of 2]-Minibatch[  19-  19, 47.50%]: CE = 7.05142212 * 16; Err = 1.00000000 * 16; time = 0.1349s; samplesPerSecond = 118.6
 Epoch[ 1 of 2]-Minibatch[  20-  20, 50.00%]: CE = 7.63081360 * 16; Err = 1.00000000 * 16; time = 0.1349s; samplesPerSecond = 118.6
 Epoch[ 1 of 2]-Minibatch[  21-  21, 52.50%]: CE = 7.51535034 * 16; Err = 1.00000000 * 16; time = 0.1348s; samplesPerSecond = 118.7
 Epoch[ 1 of 2]-Minibatch[  22-  22, 55.00%]: CE = 7.26420593 * 16; Err = 1.00000000 * 16; time = 0.1366s; samplesPerSecond = 117.1
 Epoch[ 1 of 2]-Minibatch[  23-  23, 57.50%]: CE = 7.27224731 * 16; Err = 1.00000000 * 16; time = 0.1346s; samplesPerSecond = 118.9
 Epoch[ 1 of 2]-Minibatch[  24-  24, 60.00%]: CE = 7.64137268 * 16; Err = 1.00000000 * 16; time = 0.1349s; samplesPerSecond = 118.6
 Epoch[ 1 of 2]-Minibatch[  25-  25, 62.50%]: CE = 7.29034424 * 16; Err = 1.00000000 * 16; time = 0.1347s; samplesPerSecond = 118.8
 Epoch[ 1 of 2]-Minibatch[  26-  26, 65.00%]: CE = 7.35882568 * 16; Err = 1.00000000 * 16; time = 0.1342s; samplesPerSecond = 119.2
 Epoch[ 1 of 2]-Minibatch[  27-  27, 67.50%]: CE = 7.42541504 * 16; Err = 1.00000000 * 16; time = 0.1348s; samplesPerSecond = 118.7
 Epoch[ 1 of 2]-Minibatch[  28-  28, 70.00%]: CE = 7.26679993 * 16; Err = 1.00000000 * 16; time = 0.1356s; samplesPerSecond = 118.0
 Epoch[ 1 of 2]-Minibatch[  29-  29, 72.50%]: CE = 7.46571350 * 16; Err = 1.00000000 * 16; time = 0.1346s; samplesPerSecond = 118.9
 Epoch[ 1 of 2]-Minibatch[  30-  30, 75.00%]: CE = 7.40684509 * 16; Err = 1.00000000 * 16; time = 0.1367s; samplesPerSecond = 117.0
 Epoch[ 1 of 2]-Minibatch[  31-  31, 77.50%]: CE = 7.51275635 * 16; Err = 1.00000000 * 16; time = 0.1346s; samplesPerSecond = 118.9
 Epoch[ 1 of 2]-Minibatch[  32-  32, 80.00%]: CE = 7.10246277 * 16; Err = 1.00000000 * 16; time = 0.1370s; samplesPerSecond = 116.8
 Epoch[ 1 of 2]-Minibatch[  33-  33, 82.50%]: CE = 7.45373535 * 16; Err = 1.00000000 * 16; time = 0.1343s; samplesPerSecond = 119.1
 Epoch[ 1 of 2]-Minibatch[  34-  34, 85.00%]: CE = 7.57199097 * 16; Err = 1.00000000 * 16; time = 0.1366s; samplesPerSecond = 117.1
 Epoch[ 1 of 2]-Minibatch[  35-  35, 87.50%]: CE = 7.47341919 * 16; Err = 1.00000000 * 16; time = 0.1380s; samplesPerSecond = 115.9
 Epoch[ 1 of 2]-Minibatch[  36-  36, 90.00%]: CE = 7.41589355 * 16; Err = 1.00000000 * 16; time = 0.1381s; samplesPerSecond = 115.8
 Epoch[ 1 of 2]-Minibatch[  37-  37, 92.50%]: CE = 7.52444458 * 16; Err = 1.00000000 * 16; time = 0.1371s; samplesPerSecond = 116.7
 Epoch[ 1 of 2]-Minibatch[  38-  38, 95.00%]: CE = 7.14636230 * 16; Err = 1.00000000 * 16; time = 0.1348s; samplesPerSecond = 118.7
 Epoch[ 1 of 2]-Minibatch[  39-  39, 97.50%]: CE = 7.08407593 * 16; Err = 1.00000000 * 16; time = 0.1345s; samplesPerSecond = 118.9
 Epoch[ 1 of 2]-Minibatch[  40-  40, 100.00%]: CE = 7.27563477 * 16; Err = 1.00000000 * 16; time = 0.1345s; samplesPerSecond = 119.0
Finished Epoch[ 1 of 2]: [Training] CE = 7.70680389 * 640; Err = 1.00000000 * 640; totalSamplesSeen = 640; learningRatePerSample = 0.00062499999; epochTime=10.0843s
SGD: Saving checkpoint model './Output/alexnet/AlexNet.1'

Starting Epoch 2: learning rate per sample = 0.000625  effective momentum = 0.000000  momentum as time constant = 0.0 samples
starting epoch 2 at record count 640, and file position 0
already there from last epoch

Starting minibatch loop.
 Epoch[ 2 of 2]-Minibatch[   1-   1, 2.50%]: CE = 7.49566269 * 16; Err = 1.00000000 * 16; time = 0.0376s; samplesPerSecond = 425.6
 Epoch[ 2 of 2]-Minibatch[   2-   2, 5.00%]: CE = 7.29771233 * 16; Err = 1.00000000 * 16; time = 0.0355s; samplesPerSecond = 451.3
 Epoch[ 2 of 2]-Minibatch[   3-   3, 7.50%]: CE = 7.05657578 * 16; Err = 1.00000000 * 16; time = 0.0349s; samplesPerSecond = 458.3
 Epoch[ 2 of 2]-Minibatch[   4-   4, 10.00%]: CE = 7.08620834 * 16; Err = 1.00000000 * 16; time = 0.0352s; samplesPerSecond = 454.4
 Epoch[ 2 of 2]-Minibatch[   5-   5, 12.50%]: CE = 9.33569527 * 16; Err = 1.00000000 * 16; time = 0.0353s; samplesPerSecond = 452.7
 Epoch[ 2 of 2]-Minibatch[   6-   6, 15.00%]: CE = 6.97233963 * 16; Err = 1.00000000 * 16; time = 0.0354s; samplesPerSecond = 452.4
 Epoch[ 2 of 2]-Minibatch[   7-   7, 17.50%]: CE = 7.05388641 * 16; Err = 1.00000000 * 16; time = 0.0354s; samplesPerSecond = 452.5
 Epoch[ 2 of 2]-Minibatch[   8-   8, 20.00%]: CE = 6.88942337 * 16; Err = 1.00000000 * 16; time = 0.0354s; samplesPerSecond = 451.7
 Epoch[ 2 of 2]-Minibatch[   9-   9, 22.50%]: CE = 6.83317184 * 16; Err = 1.00000000 * 16; time = 0.0355s; samplesPerSecond = 451.2
 Epoch[ 2 of 2]-Minibatch[  10-  10, 25.00%]: CE = 7.05678558 * 16; Err = 1.00000000 * 16; time = 0.0355s; samplesPerSecond = 450.6
 Epoch[ 2 of 2]-Minibatch[  11-  11, 27.50%]: CE = 6.78171539 * 16; Err = 1.00000000 * 16; time = 0.0355s; samplesPerSecond = 450.9
 Epoch[ 2 of 2]-Minibatch[  12-  12, 30.00%]: CE = 7.06445312 * 16; Err = 1.00000000 * 16; time = 0.0353s; samplesPerSecond = 452.7
 Epoch[ 2 of 2]-Minibatch[  13-  13, 32.50%]: CE = 6.86841583 * 16; Err = 1.00000000 * 16; time = 0.0355s; samplesPerSecond = 450.4
 Epoch[ 2 of 2]-Minibatch[  14-  14, 35.00%]: CE = 7.20574188 * 16; Err = 1.00000000 * 16; time = 0.0354s; samplesPerSecond = 451.9
 Epoch[ 2 of 2]-Minibatch[  15-  15, 37.50%]: CE = 6.96697998 * 16; Err = 1.00000000 * 16; time = 0.0355s; samplesPerSecond = 450.5
 Epoch[ 2 of 2]-Minibatch[  16-  16, 40.00%]: CE = 7.02133179 * 16; Err = 1.00000000 * 16; time = 0.0352s; samplesPerSecond = 454.2
 Epoch[ 2 of 2]-Minibatch[  17-  17, 42.50%]: CE = 6.74705505 * 16; Err = 1.00000000 * 16; time = 0.0353s; samplesPerSecond = 453.1
 Epoch[ 2 of 2]-Minibatch[  18-  18, 45.00%]: CE = 7.03497314 * 16; Err = 1.00000000 * 16; time = 0.0353s; samplesPerSecond = 452.9
 Epoch[ 2 of 2]-Minibatch[  19-  19, 47.50%]: CE = 6.69963074 * 16; Err = 1.00000000 * 16; time = 0.0355s; samplesPerSecond = 451.1
 Epoch[ 2 of 2]-Minibatch[  20-  20, 50.00%]: CE = 7.05790710 * 16; Err = 1.00000000 * 16; time = 0.0354s; samplesPerSecond = 452.5
 Epoch[ 2 of 2]-Minibatch[  21-  21, 52.50%]: CE = 6.98837280 * 16; Err = 1.00000000 * 16; time = 0.0353s; samplesPerSecond = 453.3
 Epoch[ 2 of 2]-Minibatch[  22-  22, 55.00%]: CE = 6.80830383 * 16; Err = 1.00000000 * 16; time = 0.0354s; samplesPerSecond = 452.5
 Epoch[ 2 of 2]-Minibatch[  23-  23, 57.50%]: CE = 6.78684998 * 16; Err = 1.00000000 * 16; time = 0.0355s; samplesPerSecond = 450.5
 Epoch[ 2 of 2]-Minibatch[  24-  24, 60.00%]: CE = 6.94689941 * 16; Err = 1.00000000 * 16; time = 0.0355s; samplesPerSecond = 450.4
 Epoch[ 2 of 2]-Minibatch[  25-  25, 62.50%]: CE = 6.70758057 * 16; Err = 1.00000000 * 16; time = 0.0351s; samplesPerSecond = 455.3
 Epoch[ 2 of 2]-Minibatch[  26-  26, 65.00%]: CE = 6.80212402 * 16; Err = 1.00000000 * 16; time = 0.0355s; samplesPerSecond = 450.5
 Epoch[ 2 of 2]-Minibatch[  27-  27, 67.50%]: CE = 6.81611633 * 16; Err = 1.00000000 * 16; time = 0.0353s; samplesPerSecond = 453.3
 Epoch[ 2 of 2]-Minibatch[  28-  28, 70.00%]: CE = 6.86538696 * 16; Err = 1.00000000 * 16; time = 0.0354s; samplesPerSecond = 452.0
 Epoch[ 2 of 2]-Minibatch[  29-  29, 72.50%]: CE = 6.89639282 * 16; Err = 1.00000000 * 16; time = 0.0354s; samplesPerSecond = 451.7
 Epoch[ 2 of 2]-Minibatch[  30-  30, 75.00%]: CE = 7.02709961 * 16; Err = 1.00000000 * 16; time = 0.0348s; samplesPerSecond = 459.7
 Epoch[ 2 of 2]-Minibatch[  31-  31, 77.50%]: CE = 7.01466370 * 16; Err = 1.00000000 * 16; time = 0.0355s; samplesPerSecond = 451.3
 Epoch[ 2 of 2]-Minibatch[  32-  32, 80.00%]: CE = 6.74604797 * 16; Err = 1.00000000 * 16; time = 0.0352s; samplesPerSecond = 454.2
 Epoch[ 2 of 2]-Minibatch[  33-  33, 82.50%]: CE = 6.94963074 * 16; Err = 1.00000000 * 16; time = 0.0352s; samplesPerSecond = 454.8
 Epoch[ 2 of 2]-Minibatch[  34-  34, 85.00%]: CE = 7.00981140 * 16; Err = 1.00000000 * 16; time = 0.0354s; samplesPerSecond = 451.4
 Epoch[ 2 of 2]-Minibatch[  35-  35, 87.50%]: CE = 7.05850220 * 16; Err = 1.00000000 * 16; time = 0.0354s; samplesPerSecond = 451.9
 Epoch[ 2 of 2]-Minibatch[  36-  36, 90.00%]: CE = 6.95710754 * 16; Err = 1.00000000 * 16; time = 0.0352s; samplesPerSecond = 454.9
 Epoch[ 2 of 2]-Minibatch[  37-  37, 92.50%]: CE = 6.99945068 * 16; Err = 1.00000000 * 16; time = 0.0353s; samplesPerSecond = 453.0
 Epoch[ 2 of 2]-Minibatch[  38-  38, 95.00%]: CE = 6.67935181 * 16; Err = 1.00000000 * 16; time = 0.0352s; samplesPerSecond = 454.0
 Epoch[ 2 of 2]-Minibatch[  39-  39, 97.50%]: CE = 6.64297485 * 16; Err = 1.00000000 * 16; time = 0.0354s; samplesPerSecond = 452.4
 Epoch[ 2 of 2]-Minibatch[  40-  40, 100.00%]: CE = 6.86492920 * 16; Err = 1.00000000 * 16; time = 0.0347s; samplesPerSecond = 461.0
Finished Epoch[ 2 of 2]: [Training] CE = 7.00233154 * 640; Err = 1.00000000 * 640; totalSamplesSeen = 1280; learningRatePerSample = 0.00062499999; epochTime=1.41755s
SGD: Saving checkpoint model './Output/alexnet/AlexNet'

Action "train" complete.

COMPLETED.
